[2025-04-08T20:03:38.903+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27466) exited with exit code 1 - re-launching
[2025-04-08T20:03:38.909+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27474
[2025-04-08T20:03:39.030+0000] {executor_loader.py:258} INFO - Loaded executor: SequentialExecutor
[2025-04-08T20:03:39.081+0000] {scheduler_job_runner.py:950} INFO - Starting the scheduler
[2025-04-08T20:03:39.082+0000] {scheduler_job_runner.py:957} INFO - Processing each file at most -1 times
[2025-04-08T20:03:39.092+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27477
[2025-04-08T20:03:39.095+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T20:03:39.099+0000] {settings.py:63} INFO - Configured default timezone UTC
[2025-04-08T20:03:39.964+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27474) exited with exit code 1 - re-launching
[2025-04-08T20:03:39.975+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27501
[2025-04-08T20:03:40.497+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27501) exited with exit code 1 - re-launching
[2025-04-08T20:03:40.507+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27512
[2025-04-08T20:03:41.563+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27512) exited with exit code 1 - re-launching
[2025-04-08T20:03:41.570+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27533
[2025-04-08T20:03:42.565+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27533) exited with exit code 1 - re-launching
[2025-04-08T20:03:42.574+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27554
[2025-04-08T20:03:42.854+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27554) exited with exit code 1 - re-launching
[2025-04-08T20:03:42.863+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27561
[2025-04-08T20:03:43.924+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27561) exited with exit code 1 - re-launching
[2025-04-08T20:03:43.932+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27586
[2025-04-08T20:03:44.974+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27586) exited with exit code 1 - re-launching
[2025-04-08T20:03:44.980+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27604
[2025-04-08T20:03:46.023+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27604) exited with exit code 1 - re-launching
[2025-04-08T20:03:46.030+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27605
[2025-04-08T20:03:47.071+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27605) exited with exit code 1 - re-launching
[2025-04-08T20:03:47.077+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27618
[2025-04-08T20:03:47.635+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27618) exited with exit code 1 - re-launching
[2025-04-08T20:03:47.641+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27621
[2025-04-08T20:03:48.696+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27621) exited with exit code 1 - re-launching
[2025-04-08T20:03:48.702+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27630
[2025-04-08T20:03:49.749+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27630) exited with exit code 1 - re-launching
[2025-04-08T20:03:49.756+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27641
Dag run  in running state
Dag information Queued at: 2025-04-08 20:03:49.951100+00:00 hash info: f09ca1d289afa72bc212c758a11203e8
[2025-04-08T20:03:50.320+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:03:50.323+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:03:50.324+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:03:50.328+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:03:50.329+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_prices', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-08T20:03:50.329+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_prices', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:03:50.332+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_prices', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:03:50.556+0000] {scheduler_job_runner.py:1016} ERROR - Exception when executing SchedulerJob._run_scheduler_loop
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/jobs/scheduler_job_runner.py", line 999, in _execute
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/jobs/scheduler_job_runner.py", line 1138, in _run_scheduler_loop
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/jobs/scheduler_job_runner.py", line 1252, in _do_scheduling
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/utils/retries.py", line 93, in wrapped_function
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/tenacity/__init__.py", line 445, in __iter__
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/tenacity/__init__.py", line 378, in iter
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/tenacity/__init__.py", line 400, in <lambda>
  File "/home/gloria/anaconda3/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/gloria/anaconda3/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/utils/retries.py", line 102, in wrapped_function
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/jobs/scheduler_job_runner.py", line 1622, in _schedule_all_dag_runs
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/jobs/scheduler_job_runner.py", line 1649, in _schedule_dag_run
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/models/dagbag.py", line 221, in get_dag
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/models/dagbag.py", line 304, in _add_dag_from_db
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/models/dag.py", line 1780, in subdags
ModuleNotFoundError: No module named 'airflow.operators'
[2025-04-08T20:03:50.568+0000] {process_utils.py:132} INFO - Sending 15 to group 27641. PIDs of all processes in the group: []
[2025-04-08T20:03:50.568+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 27641
[2025-04-08T20:03:50.569+0000] {process_utils.py:101} INFO - Sending the signal 15 to process 27641 as process group is missing.
[2025-04-08T20:03:50.569+0000] {scheduler_job_runner.py:1029} INFO - Exited execute loop
[2025-04-08T20:03:52.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:03:53.226+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:03:53.242+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:03:53.243+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:03:53.249+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:03:53.363+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:03:53.406+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:03:53.474+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:03:49.932668+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:04:00.412+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_prices', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=1, map_index=-1)
[2025-04-08T20:04:00.422+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_prices, run_id=manual__2025-04-08T20:03:49.932668+00:00, map_index=-1, run_start_date=2025-04-08 20:03:53.601455+00:00, run_end_date=2025-04-08 20:03:59.606632+00:00, run_duration=6.005177, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=34, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-08 20:03:50.325650+00:00, queued_by_job_id=33, pid=27691
[2025-04-08T20:04:00.509+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:04:00.510+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:04:00.511+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:04:00.513+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:04:00.513+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-08T20:04:00.513+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:04:00.516+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:04:03.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:04:04.237+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:04:04.253+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:04:04.254+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:04:04.260+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:04:04.358+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:04:04.405+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:04:04.482+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:03:49.932668+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:04:05.768+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=1, map_index=-1)
[2025-04-08T20:04:05.775+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=manual__2025-04-08T20:03:49.932668+00:00, map_index=-1, run_start_date=2025-04-08 20:04:04.595552+00:00, run_end_date=2025-04-08 20:04:04.957362+00:00, run_duration=0.36181, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=35, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-08 20:04:00.511657+00:00, queued_by_job_id=33, pid=27881
[2025-04-08T20:04:05.848+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:04:05.849+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:04:05.849+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:04:05.852+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:04:05.853+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-08T20:04:05.853+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:04:05.857+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:04:07.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:04:08.290+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:04:08.304+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:04:08.305+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:04:08.310+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:04:08.394+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:04:08.423+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:04:08.474+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:04:09.709+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=1, map_index=-1)
[2025-04-08T20:04:09.715+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=manual__2025-04-08T20:03:49.932668+00:00, map_index=-1, run_start_date=2025-04-08 20:04:08.579461+00:00, run_end_date=2025-04-08 20:04:08.865705+00:00, run_duration=0.286244, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=36, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-08 20:04:05.850464+00:00, queued_by_job_id=33, pid=27908
[2025-04-08T20:08:39.192+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T20:08:39.197+0000] {scheduler_job_runner.py:1972} INFO - Marked 1 SchedulerJob instances as failed
[2025-04-08T20:09:09.309+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:09:09.309+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:09:09.310+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:09:09.314+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:09:09.315+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-08T20:09:09.315+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:09:09.321+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:09:11.640+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:09:12.124+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:09:12.138+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:09:12.138+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:09:12.144+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:09:12.224+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:09:12.253+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:09:12.304+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:09:13.439+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=2, map_index=-1)
[2025-04-08T20:09:13.445+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=manual__2025-04-08T20:03:49.932668+00:00, map_index=-1, run_start_date=2025-04-08 20:09:12.404586+00:00, run_end_date=2025-04-08 20:09:12.660241+00:00, run_duration=0.255655, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=37, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-08 20:09:09.311659+00:00, queued_by_job_id=33, pid=31973
[2025-04-08T20:09:13.495+0000] {dagrun.py:823} ERROR - Marking run <DagRun Download_Stock_Price @ 2025-04-08 20:03:49.932668+00:00: manual__2025-04-08T20:03:49.932668+00:00, state:running, queued_at: 2025-04-08 20:03:49.951100+00:00. externally triggered: True> failed
Dag run  in failure state
Dag information:Download_Stock_Price Run id: manual__2025-04-08T20:03:49.932668+00:00 external trigger: True
Failed with message: task_failure
[2025-04-08T20:09:13.496+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-08 20:03:49.932668+00:00, run_id=manual__2025-04-08T20:03:49.932668+00:00, run_start_date=2025-04-08 20:03:50.267196+00:00, run_end_date=2025-04-08 20:09:13.496574+00:00, run_duration=323.229378, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-04-07 20:03:49.932668+00:00, data_interval_end=2025-04-08 20:03:49.932668+00:00, dag_hash=f09ca1d289afa72bc212c758a11203e8
[2025-04-08T20:13:39.249+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
Dag run  in running state
Dag information Queued at: 2025-04-08 20:13:41.486883+00:00 hash info: 072245be002b3cf60ac84f51d56fa6a8
[2025-04-08T20:13:42.303+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>
[2025-04-08T20:13:42.304+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:13:42.304+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>
[2025-04-08T20:13:42.306+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:13:42.307+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_prices', run_id='manual__2025-04-08T20:13:41.471091+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-08T20:13:42.307+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_prices', 'manual__2025-04-08T20:13:41.471091+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:13:42.310+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_prices', 'manual__2025-04-08T20:13:41.471091+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:13:44.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:13:45.180+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:13:45.193+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:13:45.194+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:13:45.199+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:13:45.276+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:13:45.316+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:13:45.379+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:13:41.471091+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:13:50.254+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_prices', run_id='manual__2025-04-08T20:13:41.471091+00:00', try_number=1, map_index=-1)
[2025-04-08T20:13:50.260+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_prices, run_id=manual__2025-04-08T20:13:41.471091+00:00, map_index=-1, run_start_date=2025-04-08 20:13:45.545824+00:00, run_end_date=2025-04-08 20:13:49.447450+00:00, run_duration=3.901626, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=38, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-08 20:13:42.305240+00:00, queued_by_job_id=33, pid=35208
[2025-04-08T20:13:50.333+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>
[2025-04-08T20:13:50.334+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:13:50.334+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>
[2025-04-08T20:13:50.337+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:13:50.337+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T20:13:41.471091+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-08T20:13:50.338+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T20:13:41.471091+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:13:50.341+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T20:13:41.471091+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:13:52.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:13:53.047+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:13:53.061+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:13:53.062+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:13:53.067+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:13:53.149+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:13:53.178+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:13:53.229+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:13:41.471091+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:13:54.698+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T20:13:41.471091+00:00', try_number=1, map_index=-1)
[2025-04-08T20:13:54.704+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=manual__2025-04-08T20:13:41.471091+00:00, map_index=-1, run_start_date=2025-04-08 20:13:53.333545+00:00, run_end_date=2025-04-08 20:13:53.709907+00:00, run_duration=0.376362, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=39, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-08 20:13:50.335454+00:00, queued_by_job_id=33, pid=35283
[2025-04-08T20:13:54.775+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>
[2025-04-08T20:13:54.776+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:13:54.777+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>
[2025-04-08T20:13:54.780+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:13:54.781+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T20:13:41.471091+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-08T20:13:54.782+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T20:13:41.471091+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:13:54.785+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T20:13:41.471091+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:13:57.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:13:58.149+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:13:58.163+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:13:58.163+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:13:58.169+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:13:58.251+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:13:58.280+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:13:58.329+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:13:41.471091+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:13:59.635+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T20:13:41.471091+00:00', try_number=1, map_index=-1)
[2025-04-08T20:13:59.643+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=manual__2025-04-08T20:13:41.471091+00:00, map_index=-1, run_start_date=2025-04-08 20:13:58.430054+00:00, run_end_date=2025-04-08 20:13:58.749364+00:00, run_duration=0.31931, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=40, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-08 20:13:54.778464+00:00, queued_by_job_id=33, pid=35406
[2025-04-08T20:13:59.695+0000] {dagrun.py:854} INFO - Marking run <DagRun Download_Stock_Price @ 2025-04-08 20:13:41.471091+00:00: manual__2025-04-08T20:13:41.471091+00:00, state:running, queued_at: 2025-04-08 20:13:41.486883+00:00. externally triggered: True> successful
Dag run in success state
Dag run start:2025-04-08 20:13:42.272832+00:00 end:2025-04-08 20:13:59.695760+00:00
[2025-04-08T20:13:59.695+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-08 20:13:41.471091+00:00, run_id=manual__2025-04-08T20:13:41.471091+00:00, run_start_date=2025-04-08 20:13:42.272832+00:00, run_end_date=2025-04-08 20:13:59.695760+00:00, run_duration=17.422928, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-04-07 20:13:41.471091+00:00, data_interval_end=2025-04-08 20:13:41.471091+00:00, dag_hash=072245be002b3cf60ac84f51d56fa6a8
