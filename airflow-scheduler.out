[2025-04-09T17:48:32.934+0000] {executor_loader.py:258} INFO - Loaded executor: SequentialExecutor
[2025-04-09T17:48:33.014+0000] {scheduler_job_runner.py:950} INFO - Starting the scheduler
[2025-04-09T17:48:33.016+0000] {scheduler_job_runner.py:957} INFO - Processing each file at most -1 times
[2025-04-09T17:48:33.029+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 11181
[2025-04-09T17:48:33.032+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T17:48:33.036+0000] {settings.py:63} INFO - Configured default timezone UTC
[2025-04-09T17:48:33.052+0000] {scheduler_job_runner.py:1972} INFO - Marked 1 SchedulerJob instances as failed
[2025-04-09T17:53:33.123+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T17:58:33.167+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T18:03:33.210+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T18:08:33.259+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T18:13:33.301+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T18:18:33.353+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T18:23:33.396+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T18:28:33.438+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T18:33:33.480+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T18:38:33.520+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T18:43:33.558+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T18:43:57.577+0000] {manager.py:537} INFO - DAG Download_Stock_Price is missing and will be deactivated.
[2025-04-09T18:43:57.583+0000] {manager.py:549} INFO - Deactivated 1 DAGs which are no longer present in file.
[2025-04-09T18:43:57.586+0000] {manager.py:553} INFO - Deleted DAG Download_Stock_Price in serialized_dag table
[2025-04-09T18:48:33.615+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T18:49:52.289+0000] {scheduler_job_runner.py:1526} INFO - DAG Download_Stock_Price is at (or above) max_active_runs (1 of 1), not creating any more runs
Dag run  in running state
Dag information Queued at: 2025-04-09 18:49:52.239946+00:00 hash info: e66153a96998ad7e802ecac0603d9ebf
[2025-04-09T18:49:52.340+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_price scheduled__2025-04-08T18:44:00+00:00 [scheduled]>
[2025-04-09T18:49:52.341+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T18:49:52.341+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_price scheduled__2025-04-08T18:44:00+00:00 [scheduled]>
[2025-04-09T18:49:52.344+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_price scheduled__2025-04-08T18:44:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T18:49:52.345+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='scheduled__2025-04-08T18:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-09T18:49:52.345+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'scheduled__2025-04-08T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T18:49:52.347+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'scheduled__2025-04-08T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T18:49:54.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T18:49:54.875+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T18:49:54.889+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T18:49:54.890+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T18:49:54.895+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T18:49:54.967+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T18:49:54.993+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T18:49:55.047+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_price scheduled__2025-04-08T18:44:00+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T18:50:00.065+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='scheduled__2025-04-08T18:44:00+00:00', try_number=1, map_index=-1)
[2025-04-09T18:50:00.075+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_price, run_id=scheduled__2025-04-08T18:44:00+00:00, map_index=-1, run_start_date=2025-04-09 18:49:55.148884+00:00, run_end_date=2025-04-09 18:49:59.319255+00:00, run_duration=4.170371, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=60, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-09 18:49:52.342692+00:00, queued_by_job_id=59, pid=30000
[2025-04-09T18:50:00.150+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database scheduled__2025-04-08T18:44:00+00:00 [scheduled]>
[2025-04-09T18:50:00.150+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T18:50:00.150+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database scheduled__2025-04-08T18:44:00+00:00 [scheduled]>
[2025-04-09T18:50:00.152+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database scheduled__2025-04-08T18:44:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T18:50:00.153+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='scheduled__2025-04-08T18:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-09T18:50:00.153+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'scheduled__2025-04-08T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T18:50:00.156+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'scheduled__2025-04-08T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T18:50:01.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T18:50:02.406+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T18:50:02.420+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T18:50:02.421+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T18:50:02.426+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T18:50:02.499+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T18:50:02.526+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T18:50:02.571+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database scheduled__2025-04-08T18:44:00+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T18:50:03.724+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='scheduled__2025-04-08T18:44:00+00:00', try_number=1, map_index=-1)
[2025-04-09T18:50:03.730+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=scheduled__2025-04-08T18:44:00+00:00, map_index=-1, run_start_date=2025-04-09 18:50:02.671961+00:00, run_end_date=2025-04-09 18:50:02.999084+00:00, run_duration=0.327123, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=61, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-09 18:50:00.151494+00:00, queued_by_job_id=59, pid=30031
[2025-04-09T18:50:03.778+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price scheduled__2025-04-08T18:44:00+00:00 [scheduled]>
[2025-04-09T18:50:03.778+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T18:50:03.779+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price scheduled__2025-04-08T18:44:00+00:00 [scheduled]>
[2025-04-09T18:50:03.781+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price scheduled__2025-04-08T18:44:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T18:50:03.781+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='scheduled__2025-04-08T18:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-09T18:50:03.781+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'scheduled__2025-04-08T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T18:50:03.784+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'scheduled__2025-04-08T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T18:50:05.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T18:50:06.082+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T18:50:06.096+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T18:50:06.096+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T18:50:06.102+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T18:50:06.173+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T18:50:06.203+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T18:50:06.252+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price scheduled__2025-04-08T18:44:00+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T18:50:07.456+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='scheduled__2025-04-08T18:44:00+00:00', try_number=1, map_index=-1)
[2025-04-09T18:50:07.462+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=scheduled__2025-04-08T18:44:00+00:00, map_index=-1, run_start_date=2025-04-09 18:50:06.351801+00:00, run_end_date=2025-04-09 18:50:06.729366+00:00, run_duration=0.377565, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=62, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-09 18:50:03.779918+00:00, queued_by_job_id=59, pid=30058
[2025-04-09T18:50:07.506+0000] {dagrun.py:854} INFO - Marking run <DagRun Download_Stock_Price @ 2025-04-08 18:44:00+00:00: scheduled__2025-04-08T18:44:00+00:00, state:running, queued_at: 2025-04-09 18:49:52.239946+00:00. externally triggered: False> successful
Dag run in success state
Dag run start:2025-04-09 18:49:52.299879+00:00 end:2025-04-09 18:50:07.507656+00:00
[2025-04-09T18:50:07.507+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-08 18:44:00+00:00, run_id=scheduled__2025-04-08T18:44:00+00:00, run_start_date=2025-04-09 18:49:52.299879+00:00, run_end_date=2025-04-09 18:50:07.507656+00:00, run_duration=15.207777, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-04-08 18:44:00+00:00, data_interval_end=2025-04-09 18:44:00+00:00, dag_hash=e66153a96998ad7e802ecac0603d9ebf
[2025-04-09T18:50:07.514+0000] {dag.py:4180} INFO - Setting next_dagrun for Download_Stock_Price to 2025-04-09 18:44:00+00:00, run_after=2025-04-10 18:44:00+00:00
[2025-04-09T18:52:00.375+0000] {scheduler_job_runner.py:1526} INFO - DAG Download_Stock_Price is at (or above) max_active_runs (1 of 1), not creating any more runs
Dag run  in running state
Dag information Queued at: 2025-04-09 18:52:00.368502+00:00 hash info: ba0213d17d4ba27a475542a9fe1f1b9d
[2025-04-09T18:52:00.412+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_price scheduled__2025-04-08T18:52:00+00:00 [scheduled]>
[2025-04-09T18:52:00.413+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T18:52:00.413+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_price scheduled__2025-04-08T18:52:00+00:00 [scheduled]>
[2025-04-09T18:52:00.415+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_price scheduled__2025-04-08T18:52:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T18:52:00.416+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='scheduled__2025-04-08T18:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-09T18:52:00.416+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'scheduled__2025-04-08T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T18:52:00.419+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'scheduled__2025-04-08T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T18:52:02.204+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T18:52:02.668+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T18:52:02.683+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T18:52:02.684+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T18:52:02.688+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T18:52:02.759+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T18:52:02.784+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T18:52:02.832+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_price scheduled__2025-04-08T18:52:00+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T18:52:08.210+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='scheduled__2025-04-08T18:52:00+00:00', try_number=1, map_index=-1)
[2025-04-09T18:52:08.216+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_price, run_id=scheduled__2025-04-08T18:52:00+00:00, map_index=-1, run_start_date=2025-04-09 18:52:02.920521+00:00, run_end_date=2025-04-09 18:52:07.500977+00:00, run_duration=4.580456, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=63, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-09 18:52:00.414292+00:00, queued_by_job_id=59, pid=30571
[2025-04-09T18:52:08.279+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database scheduled__2025-04-08T18:52:00+00:00 [scheduled]>
[2025-04-09T18:52:08.280+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T18:52:08.280+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database scheduled__2025-04-08T18:52:00+00:00 [scheduled]>
[2025-04-09T18:52:08.282+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database scheduled__2025-04-08T18:52:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T18:52:08.283+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='scheduled__2025-04-08T18:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-09T18:52:08.283+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'scheduled__2025-04-08T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T18:52:08.286+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'scheduled__2025-04-08T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T18:52:10.067+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T18:52:10.524+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T18:52:10.538+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T18:52:10.539+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T18:52:10.544+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T18:52:10.618+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T18:52:10.645+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T18:52:10.689+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database scheduled__2025-04-08T18:52:00+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T18:52:11.779+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='scheduled__2025-04-08T18:52:00+00:00', try_number=1, map_index=-1)
[2025-04-09T18:52:11.784+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=scheduled__2025-04-08T18:52:00+00:00, map_index=-1, run_start_date=2025-04-09 18:52:10.782477+00:00, run_end_date=2025-04-09 18:52:11.070785+00:00, run_duration=0.288308, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=64, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-09 18:52:08.281511+00:00, queued_by_job_id=59, pid=30597
[2025-04-09T18:52:11.832+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price scheduled__2025-04-08T18:52:00+00:00 [scheduled]>
[2025-04-09T18:52:11.833+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T18:52:11.833+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price scheduled__2025-04-08T18:52:00+00:00 [scheduled]>
[2025-04-09T18:52:11.835+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price scheduled__2025-04-08T18:52:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T18:52:11.836+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='scheduled__2025-04-08T18:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-09T18:52:11.836+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'scheduled__2025-04-08T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T18:52:11.839+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'scheduled__2025-04-08T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T18:52:13.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T18:52:14.094+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T18:52:14.108+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T18:52:14.109+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T18:52:14.113+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T18:52:14.184+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T18:52:14.209+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T18:52:14.254+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price scheduled__2025-04-08T18:52:00+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T18:52:15.385+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='scheduled__2025-04-08T18:52:00+00:00', try_number=1, map_index=-1)
[2025-04-09T18:52:15.390+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=scheduled__2025-04-08T18:52:00+00:00, map_index=-1, run_start_date=2025-04-09 18:52:14.347479+00:00, run_end_date=2025-04-09 18:52:14.678957+00:00, run_duration=0.331478, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=65, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-09 18:52:11.834290+00:00, queued_by_job_id=59, pid=30628
[2025-04-09T18:52:15.431+0000] {dagrun.py:854} INFO - Marking run <DagRun Download_Stock_Price @ 2025-04-08 18:52:00+00:00: scheduled__2025-04-08T18:52:00+00:00, state:running, queued_at: 2025-04-09 18:52:00.368502+00:00. externally triggered: False> successful
Dag run in success state
Dag run start:2025-04-09 18:52:00.384301+00:00 end:2025-04-09 18:52:15.432475+00:00
[2025-04-09T18:52:15.432+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-08 18:52:00+00:00, run_id=scheduled__2025-04-08T18:52:00+00:00, run_start_date=2025-04-09 18:52:00.384301+00:00, run_end_date=2025-04-09 18:52:15.432475+00:00, run_duration=15.048174, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-04-08 18:52:00+00:00, data_interval_end=2025-04-09 18:52:00+00:00, dag_hash=ba0213d17d4ba27a475542a9fe1f1b9d
[2025-04-09T18:52:15.437+0000] {dag.py:4180} INFO - Setting next_dagrun for Download_Stock_Price to 2025-04-09 18:52:00+00:00, run_after=2025-04-10 18:52:00+00:00
[2025-04-09T18:53:33.659+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T18:58:33.702+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T19:03:33.726+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
Dag run  in running state
Dag information Queued at: 2025-04-09 19:04:26.436745+00:00 hash info: ba0213d17d4ba27a475542a9fe1f1b9d
[2025-04-09T19:04:27.155+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_price manual__2025-04-09T19:04:26.406588+00:00 [scheduled]>
[2025-04-09T19:04:27.156+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T19:04:27.156+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_price manual__2025-04-09T19:04:26.406588+00:00 [scheduled]>
[2025-04-09T19:04:27.158+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_price manual__2025-04-09T19:04:26.406588+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T19:04:27.159+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='manual__2025-04-09T19:04:26.406588+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-09T19:04:27.159+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'manual__2025-04-09T19:04:26.406588+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T19:04:27.162+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'manual__2025-04-09T19:04:26.406588+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T19:04:28.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T19:04:29.433+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T19:04:29.448+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T19:04:29.448+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T19:04:29.454+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T19:04:29.527+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T19:04:29.553+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T19:04:29.600+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_price manual__2025-04-09T19:04:26.406588+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T19:04:35.047+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='manual__2025-04-09T19:04:26.406588+00:00', try_number=1, map_index=-1)
[2025-04-09T19:04:35.053+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_price, run_id=manual__2025-04-09T19:04:26.406588+00:00, map_index=-1, run_start_date=2025-04-09 19:04:29.689832+00:00, run_end_date=2025-04-09 19:04:34.177820+00:00, run_duration=4.487988, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=66, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-09 19:04:27.157474+00:00, queued_by_job_id=59, pid=34318
[2025-04-09T19:04:35.126+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-09T19:04:26.406588+00:00 [scheduled]>
[2025-04-09T19:04:35.127+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T19:04:35.127+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-09T19:04:26.406588+00:00 [scheduled]>
[2025-04-09T19:04:35.129+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-09T19:04:26.406588+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T19:04:35.130+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-09T19:04:26.406588+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-09T19:04:35.130+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-09T19:04:26.406588+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T19:04:35.133+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-09T19:04:26.406588+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T19:04:36.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T19:04:37.569+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T19:04:37.585+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T19:04:37.585+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T19:04:37.590+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T19:04:37.666+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T19:04:37.693+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T19:04:37.736+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-09T19:04:26.406588+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T19:04:38.912+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-09T19:04:26.406588+00:00', try_number=1, map_index=-1)
[2025-04-09T19:04:38.917+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=manual__2025-04-09T19:04:26.406588+00:00, map_index=-1, run_start_date=2025-04-09 19:04:37.825968+00:00, run_end_date=2025-04-09 19:04:38.109360+00:00, run_duration=0.283392, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=67, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-09 19:04:35.128130+00:00, queued_by_job_id=59, pid=34403
[2025-04-09T19:04:38.974+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-09T19:04:26.406588+00:00 [scheduled]>
[2025-04-09T19:04:38.975+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T19:04:38.975+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-09T19:04:26.406588+00:00 [scheduled]>
[2025-04-09T19:04:38.977+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-09T19:04:26.406588+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T19:04:38.978+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-09T19:04:26.406588+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-09T19:04:38.978+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-09T19:04:26.406588+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T19:04:38.981+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-09T19:04:26.406588+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T19:04:41.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T19:04:41.575+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T19:04:41.591+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T19:04:41.592+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T19:04:41.597+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T19:04:41.674+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T19:04:41.704+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T19:04:41.758+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-09T19:04:26.406588+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T19:04:43.014+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-09T19:04:26.406588+00:00', try_number=1, map_index=-1)
[2025-04-09T19:04:43.020+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=manual__2025-04-09T19:04:26.406588+00:00, map_index=-1, run_start_date=2025-04-09 19:04:41.854619+00:00, run_end_date=2025-04-09 19:04:42.150195+00:00, run_duration=0.295576, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=68, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-09 19:04:38.976183+00:00, queued_by_job_id=59, pid=34466
[2025-04-09T19:04:43.068+0000] {dagrun.py:854} INFO - Marking run <DagRun Download_Stock_Price @ 2025-04-09 19:04:26.406588+00:00: manual__2025-04-09T19:04:26.406588+00:00, state:running, queued_at: 2025-04-09 19:04:26.436745+00:00. externally triggered: True> successful
Dag run in success state
Dag run start:2025-04-09 19:04:27.126088+00:00 end:2025-04-09 19:04:43.068983+00:00
[2025-04-09T19:04:43.069+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-09 19:04:26.406588+00:00, run_id=manual__2025-04-09T19:04:26.406588+00:00, run_start_date=2025-04-09 19:04:27.126088+00:00, run_end_date=2025-04-09 19:04:43.068983+00:00, run_duration=15.942895, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-04-08 18:52:00+00:00, data_interval_end=2025-04-09 18:52:00+00:00, dag_hash=ba0213d17d4ba27a475542a9fe1f1b9d
[2025-04-09T19:08:33.768+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T19:13:33.813+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T19:18:33.853+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T19:23:33.896+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T19:28:33.941+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T19:33:33.989+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T19:38:34.032+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T19:43:34.075+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T19:48:34.128+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T19:53:34.169+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T19:58:34.211+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T20:03:34.251+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
Dag run  in running state
Dag information Queued at: 2025-04-09 20:06:14.956584+00:00 hash info: ba0213d17d4ba27a475542a9fe1f1b9d
[2025-04-09T20:06:15.286+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_price manual__2025-04-09T20:06:14.907700+00:00 [scheduled]>
[2025-04-09T20:06:15.287+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T20:06:15.288+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_price manual__2025-04-09T20:06:14.907700+00:00 [scheduled]>
[2025-04-09T20:06:15.290+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_price manual__2025-04-09T20:06:14.907700+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T20:06:15.291+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='manual__2025-04-09T20:06:14.907700+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-09T20:06:15.291+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'manual__2025-04-09T20:06:14.907700+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T20:06:15.294+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'manual__2025-04-09T20:06:14.907700+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T20:06:17.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T20:06:17.885+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T20:06:17.909+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T20:06:17.910+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T20:06:17.918+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T20:06:18.035+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T20:06:18.083+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T20:06:18.140+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_price manual__2025-04-09T20:06:14.907700+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T20:06:23.276+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='manual__2025-04-09T20:06:14.907700+00:00', try_number=1, map_index=-1)
[2025-04-09T20:06:23.282+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_price, run_id=manual__2025-04-09T20:06:14.907700+00:00, map_index=-1, run_start_date=2025-04-09 20:06:18.252402+00:00, run_end_date=2025-04-09 20:06:22.563614+00:00, run_duration=4.311212, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=69, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-09 20:06:15.288916+00:00, queued_by_job_id=59, pid=52043
[2025-04-09T20:06:23.351+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-09T20:06:14.907700+00:00 [scheduled]>
[2025-04-09T20:06:23.351+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T20:06:23.352+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-09T20:06:14.907700+00:00 [scheduled]>
[2025-04-09T20:06:23.354+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-09T20:06:14.907700+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T20:06:23.354+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-09T20:06:14.907700+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-09T20:06:23.355+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-09T20:06:14.907700+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T20:06:23.358+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-09T20:06:14.907700+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T20:06:25.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T20:06:25.686+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T20:06:25.700+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T20:06:25.701+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T20:06:25.706+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T20:06:25.779+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T20:06:25.805+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T20:06:25.848+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-09T20:06:14.907700+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T20:06:26.925+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-09T20:06:14.907700+00:00', try_number=1, map_index=-1)
[2025-04-09T20:06:26.931+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=manual__2025-04-09T20:06:14.907700+00:00, map_index=-1, run_start_date=2025-04-09 20:06:25.938891+00:00, run_end_date=2025-04-09 20:06:26.214133+00:00, run_duration=0.275242, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=70, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-09 20:06:23.352769+00:00, queued_by_job_id=59, pid=52086
[2025-04-09T20:06:26.982+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-09T20:06:14.907700+00:00 [scheduled]>
[2025-04-09T20:06:26.983+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T20:06:26.983+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-09T20:06:14.907700+00:00 [scheduled]>
[2025-04-09T20:06:26.985+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-09T20:06:14.907700+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T20:06:26.985+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-09T20:06:14.907700+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-09T20:06:26.986+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-09T20:06:14.907700+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T20:06:26.989+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-09T20:06:14.907700+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T20:06:28.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T20:06:29.235+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T20:06:29.250+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T20:06:29.251+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T20:06:29.256+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T20:06:29.330+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T20:06:29.357+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T20:06:29.402+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-09T20:06:14.907700+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T20:06:30.487+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-09T20:06:14.907700+00:00', try_number=1, map_index=-1)
[2025-04-09T20:06:30.492+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=manual__2025-04-09T20:06:14.907700+00:00, map_index=-1, run_start_date=2025-04-09 20:06:29.495462+00:00, run_end_date=2025-04-09 20:06:29.780875+00:00, run_duration=0.285413, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=71, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-09 20:06:26.984245+00:00, queued_by_job_id=59, pid=52113
[2025-04-09T20:06:30.536+0000] {dagrun.py:854} INFO - Marking run <DagRun Download_Stock_Price @ 2025-04-09 20:06:14.907700+00:00: manual__2025-04-09T20:06:14.907700+00:00, state:running, queued_at: 2025-04-09 20:06:14.956584+00:00. externally triggered: True> successful
Dag run in success state
Dag run start:2025-04-09 20:06:15.248915+00:00 end:2025-04-09 20:06:30.537148+00:00
[2025-04-09T20:06:30.537+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-09 20:06:14.907700+00:00, run_id=manual__2025-04-09T20:06:14.907700+00:00, run_start_date=2025-04-09 20:06:15.248915+00:00, run_end_date=2025-04-09 20:06:30.537148+00:00, run_duration=15.288233, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-04-08 18:52:00+00:00, data_interval_end=2025-04-09 18:52:00+00:00, dag_hash=ba0213d17d4ba27a475542a9fe1f1b9d
[2025-04-09T20:08:34.294+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
