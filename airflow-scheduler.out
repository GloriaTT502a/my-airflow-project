[2025-04-08T20:03:38.903+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27466) exited with exit code 1 - re-launching
[2025-04-08T20:03:38.909+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27474
[2025-04-08T20:03:39.030+0000] {executor_loader.py:258} INFO - Loaded executor: SequentialExecutor
[2025-04-08T20:03:39.081+0000] {scheduler_job_runner.py:950} INFO - Starting the scheduler
[2025-04-08T20:03:39.082+0000] {scheduler_job_runner.py:957} INFO - Processing each file at most -1 times
[2025-04-08T20:03:39.092+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27477
[2025-04-08T20:03:39.095+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T20:03:39.099+0000] {settings.py:63} INFO - Configured default timezone UTC
[2025-04-08T20:03:39.964+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27474) exited with exit code 1 - re-launching
[2025-04-08T20:03:39.975+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27501
[2025-04-08T20:03:40.497+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27501) exited with exit code 1 - re-launching
[2025-04-08T20:03:40.507+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27512
[2025-04-08T20:03:41.563+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27512) exited with exit code 1 - re-launching
[2025-04-08T20:03:41.570+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27533
[2025-04-08T20:03:42.565+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27533) exited with exit code 1 - re-launching
[2025-04-08T20:03:42.574+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27554
[2025-04-08T20:03:42.854+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27554) exited with exit code 1 - re-launching
[2025-04-08T20:03:42.863+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27561
[2025-04-08T20:03:43.924+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27561) exited with exit code 1 - re-launching
[2025-04-08T20:03:43.932+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27586
[2025-04-08T20:03:44.974+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27586) exited with exit code 1 - re-launching
[2025-04-08T20:03:44.980+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27604
[2025-04-08T20:03:46.023+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27604) exited with exit code 1 - re-launching
[2025-04-08T20:03:46.030+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27605
[2025-04-08T20:03:47.071+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27605) exited with exit code 1 - re-launching
[2025-04-08T20:03:47.077+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27618
[2025-04-08T20:03:47.635+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27618) exited with exit code 1 - re-launching
[2025-04-08T20:03:47.641+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27621
[2025-04-08T20:03:48.696+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27621) exited with exit code 1 - re-launching
[2025-04-08T20:03:48.702+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27630
[2025-04-08T20:03:49.749+0000] {manager.py:280} WARNING - DagFileProcessorManager (PID=27630) exited with exit code 1 - re-launching
[2025-04-08T20:03:49.756+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 27641
Dag run  in running state
Dag information Queued at: 2025-04-08 20:03:49.951100+00:00 hash info: f09ca1d289afa72bc212c758a11203e8
[2025-04-08T20:03:50.320+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:03:50.323+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:03:50.324+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:03:50.328+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:03:50.329+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_prices', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-08T20:03:50.329+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_prices', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:03:50.332+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_prices', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:03:50.556+0000] {scheduler_job_runner.py:1016} ERROR - Exception when executing SchedulerJob._run_scheduler_loop
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/jobs/scheduler_job_runner.py", line 999, in _execute
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/jobs/scheduler_job_runner.py", line 1138, in _run_scheduler_loop
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/jobs/scheduler_job_runner.py", line 1252, in _do_scheduling
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/utils/retries.py", line 93, in wrapped_function
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/tenacity/__init__.py", line 445, in __iter__
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/tenacity/__init__.py", line 378, in iter
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/tenacity/__init__.py", line 400, in <lambda>
  File "/home/gloria/anaconda3/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/gloria/anaconda3/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/utils/retries.py", line 102, in wrapped_function
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/jobs/scheduler_job_runner.py", line 1622, in _schedule_all_dag_runs
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/jobs/scheduler_job_runner.py", line 1649, in _schedule_dag_run
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/models/dagbag.py", line 221, in get_dag
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/models/dagbag.py", line 304, in _add_dag_from_db
  File "/home/gloria/airflow_env/lib/python3.12/site-packages/airflow/models/dag.py", line 1780, in subdags
ModuleNotFoundError: No module named 'airflow.operators'
[2025-04-08T20:03:50.568+0000] {process_utils.py:132} INFO - Sending 15 to group 27641. PIDs of all processes in the group: []
[2025-04-08T20:03:50.568+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 27641
[2025-04-08T20:03:50.569+0000] {process_utils.py:101} INFO - Sending the signal 15 to process 27641 as process group is missing.
[2025-04-08T20:03:50.569+0000] {scheduler_job_runner.py:1029} INFO - Exited execute loop
[2025-04-08T20:03:52.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:03:53.226+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:03:53.242+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:03:53.243+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:03:53.249+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:03:53.363+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:03:53.406+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:03:53.474+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:03:49.932668+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:04:00.412+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_prices', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=1, map_index=-1)
[2025-04-08T20:04:00.422+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_prices, run_id=manual__2025-04-08T20:03:49.932668+00:00, map_index=-1, run_start_date=2025-04-08 20:03:53.601455+00:00, run_end_date=2025-04-08 20:03:59.606632+00:00, run_duration=6.005177, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=34, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-08 20:03:50.325650+00:00, queued_by_job_id=33, pid=27691
[2025-04-08T20:04:00.509+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:04:00.510+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:04:00.511+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:04:00.513+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:04:00.513+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-08T20:04:00.513+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:04:00.516+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:04:03.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:04:04.237+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:04:04.253+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:04:04.254+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:04:04.260+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:04:04.358+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:04:04.405+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:04:04.482+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:03:49.932668+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:04:05.768+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=1, map_index=-1)
[2025-04-08T20:04:05.775+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=manual__2025-04-08T20:03:49.932668+00:00, map_index=-1, run_start_date=2025-04-08 20:04:04.595552+00:00, run_end_date=2025-04-08 20:04:04.957362+00:00, run_duration=0.36181, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=35, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-08 20:04:00.511657+00:00, queued_by_job_id=33, pid=27881
[2025-04-08T20:04:05.848+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:04:05.849+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:04:05.849+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:04:05.852+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:04:05.853+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-08T20:04:05.853+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:04:05.857+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:04:07.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:04:08.290+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:04:08.304+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:04:08.305+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:04:08.310+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:04:08.394+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:04:08.423+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:04:08.474+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:04:09.709+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=1, map_index=-1)
[2025-04-08T20:04:09.715+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=manual__2025-04-08T20:03:49.932668+00:00, map_index=-1, run_start_date=2025-04-08 20:04:08.579461+00:00, run_end_date=2025-04-08 20:04:08.865705+00:00, run_duration=0.286244, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=36, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-08 20:04:05.850464+00:00, queued_by_job_id=33, pid=27908
[2025-04-08T20:08:39.192+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T20:08:39.197+0000] {scheduler_job_runner.py:1972} INFO - Marked 1 SchedulerJob instances as failed
[2025-04-08T20:09:09.309+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:09:09.309+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:09:09.310+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>
[2025-04-08T20:09:09.314+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:09:09.315+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-08T20:09:09.315+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:09:09.321+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T20:03:49.932668+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:09:11.640+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:09:12.124+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:09:12.138+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:09:12.138+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:09:12.144+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:09:12.224+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:09:12.253+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:09:12.304+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:03:49.932668+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:09:13.439+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T20:03:49.932668+00:00', try_number=2, map_index=-1)
[2025-04-08T20:09:13.445+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=manual__2025-04-08T20:03:49.932668+00:00, map_index=-1, run_start_date=2025-04-08 20:09:12.404586+00:00, run_end_date=2025-04-08 20:09:12.660241+00:00, run_duration=0.255655, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=37, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-08 20:09:09.311659+00:00, queued_by_job_id=33, pid=31973
[2025-04-08T20:09:13.495+0000] {dagrun.py:823} ERROR - Marking run <DagRun Download_Stock_Price @ 2025-04-08 20:03:49.932668+00:00: manual__2025-04-08T20:03:49.932668+00:00, state:running, queued_at: 2025-04-08 20:03:49.951100+00:00. externally triggered: True> failed
Dag run  in failure state
Dag information:Download_Stock_Price Run id: manual__2025-04-08T20:03:49.932668+00:00 external trigger: True
Failed with message: task_failure
[2025-04-08T20:09:13.496+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-08 20:03:49.932668+00:00, run_id=manual__2025-04-08T20:03:49.932668+00:00, run_start_date=2025-04-08 20:03:50.267196+00:00, run_end_date=2025-04-08 20:09:13.496574+00:00, run_duration=323.229378, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-04-07 20:03:49.932668+00:00, data_interval_end=2025-04-08 20:03:49.932668+00:00, dag_hash=f09ca1d289afa72bc212c758a11203e8
[2025-04-08T20:13:39.249+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
Dag run  in running state
Dag information Queued at: 2025-04-08 20:13:41.486883+00:00 hash info: 072245be002b3cf60ac84f51d56fa6a8
[2025-04-08T20:13:42.303+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>
[2025-04-08T20:13:42.304+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:13:42.304+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>
[2025-04-08T20:13:42.306+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:13:42.307+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_prices', run_id='manual__2025-04-08T20:13:41.471091+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-08T20:13:42.307+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_prices', 'manual__2025-04-08T20:13:41.471091+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:13:42.310+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_prices', 'manual__2025-04-08T20:13:41.471091+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:13:44.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:13:45.180+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:13:45.193+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:13:45.194+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:13:45.199+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:13:45.276+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:13:45.316+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:13:45.379+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T20:13:41.471091+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:13:50.254+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_prices', run_id='manual__2025-04-08T20:13:41.471091+00:00', try_number=1, map_index=-1)
[2025-04-08T20:13:50.260+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_prices, run_id=manual__2025-04-08T20:13:41.471091+00:00, map_index=-1, run_start_date=2025-04-08 20:13:45.545824+00:00, run_end_date=2025-04-08 20:13:49.447450+00:00, run_duration=3.901626, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=38, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-08 20:13:42.305240+00:00, queued_by_job_id=33, pid=35208
[2025-04-08T20:13:50.333+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>
[2025-04-08T20:13:50.334+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:13:50.334+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>
[2025-04-08T20:13:50.337+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:13:50.337+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T20:13:41.471091+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-08T20:13:50.338+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T20:13:41.471091+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:13:50.341+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T20:13:41.471091+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:13:52.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:13:53.047+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:13:53.061+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:13:53.062+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:13:53.067+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:13:53.149+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:13:53.178+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:13:53.229+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T20:13:41.471091+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:13:54.698+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T20:13:41.471091+00:00', try_number=1, map_index=-1)
[2025-04-08T20:13:54.704+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=manual__2025-04-08T20:13:41.471091+00:00, map_index=-1, run_start_date=2025-04-08 20:13:53.333545+00:00, run_end_date=2025-04-08 20:13:53.709907+00:00, run_duration=0.376362, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=39, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-08 20:13:50.335454+00:00, queued_by_job_id=33, pid=35283
[2025-04-08T20:13:54.775+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>
[2025-04-08T20:13:54.776+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T20:13:54.777+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>
[2025-04-08T20:13:54.780+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:13:41.471091+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T20:13:54.781+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T20:13:41.471091+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-08T20:13:54.782+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T20:13:41.471091+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:13:54.785+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T20:13:41.471091+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T20:13:57.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T20:13:58.149+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T20:13:58.163+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T20:13:58.163+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:13:58.169+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:13:58.251+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T20:13:58.280+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T20:13:58.329+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T20:13:41.471091+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T20:13:59.635+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T20:13:41.471091+00:00', try_number=1, map_index=-1)
[2025-04-08T20:13:59.643+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=manual__2025-04-08T20:13:41.471091+00:00, map_index=-1, run_start_date=2025-04-08 20:13:58.430054+00:00, run_end_date=2025-04-08 20:13:58.749364+00:00, run_duration=0.31931, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=40, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-08 20:13:54.778464+00:00, queued_by_job_id=33, pid=35406
[2025-04-08T20:13:59.695+0000] {dagrun.py:854} INFO - Marking run <DagRun Download_Stock_Price @ 2025-04-08 20:13:41.471091+00:00: manual__2025-04-08T20:13:41.471091+00:00, state:running, queued_at: 2025-04-08 20:13:41.486883+00:00. externally triggered: True> successful
Dag run in success state
Dag run start:2025-04-08 20:13:42.272832+00:00 end:2025-04-08 20:13:59.695760+00:00
[2025-04-08T20:13:59.695+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-08 20:13:41.471091+00:00, run_id=manual__2025-04-08T20:13:41.471091+00:00, run_start_date=2025-04-08 20:13:42.272832+00:00, run_end_date=2025-04-08 20:13:59.695760+00:00, run_duration=17.422928, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-04-07 20:13:41.471091+00:00, data_interval_end=2025-04-08 20:13:41.471091+00:00, dag_hash=072245be002b3cf60ac84f51d56fa6a8
[2025-04-08T20:18:39.324+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T20:23:39.387+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T20:28:39.438+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T20:33:39.562+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T20:38:39.620+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T20:43:39.677+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T20:48:39.729+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T20:53:39.779+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T20:58:39.825+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T21:03:39.875+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T21:08:39.938+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T21:13:39.988+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T21:18:40.032+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T21:23:40.075+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T21:28:40.123+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
Dag run  in running state
Dag information Queued at: 2025-04-08 21:33:38.738092+00:00 hash info: 072245be002b3cf60ac84f51d56fa6a8
[2025-04-08T21:33:39.351+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T21:33:38.685111+00:00 [scheduled]>
[2025-04-08T21:33:39.351+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T21:33:39.352+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T21:33:38.685111+00:00 [scheduled]>
[2025-04-08T21:33:39.355+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T21:33:38.685111+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T21:33:39.356+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_prices', run_id='manual__2025-04-08T21:33:38.685111+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-08T21:33:39.357+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_prices', 'manual__2025-04-08T21:33:38.685111+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:33:39.362+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_prices', 'manual__2025-04-08T21:33:38.685111+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:33:42.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T21:33:42.622+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T21:33:42.638+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T21:33:42.639+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:33:42.644+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:33:42.730+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:33:42.760+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:33:42.810+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T21:33:38.685111+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T21:33:46.897+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_prices', run_id='manual__2025-04-08T21:33:38.685111+00:00', try_number=1, map_index=-1)
[2025-04-08T21:33:46.916+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_prices, run_id=manual__2025-04-08T21:33:38.685111+00:00, map_index=-1, run_start_date=2025-04-08 21:33:42.909278+00:00, run_end_date=2025-04-08 21:33:46.064291+00:00, run_duration=3.155013, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=41, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-08 21:33:39.353681+00:00, queued_by_job_id=33, pid=96170
[2025-04-08T21:33:46.941+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T21:33:47.038+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:33:38.685111+00:00 [scheduled]>
[2025-04-08T21:33:47.039+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T21:33:47.040+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:33:38.685111+00:00 [scheduled]>
[2025-04-08T21:33:47.043+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:33:38.685111+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T21:33:47.044+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T21:33:38.685111+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-08T21:33:47.044+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T21:33:38.685111+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:33:47.048+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T21:33:38.685111+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:33:49.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T21:33:50.224+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T21:33:50.238+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T21:33:50.239+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:33:50.244+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:33:50.359+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:33:50.399+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:33:50.465+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:33:38.685111+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T21:33:52.296+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T21:33:38.685111+00:00', try_number=1, map_index=-1)
[2025-04-08T21:33:52.303+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=manual__2025-04-08T21:33:38.685111+00:00, map_index=-1, run_start_date=2025-04-08 21:33:50.583584+00:00, run_end_date=2025-04-08 21:33:51.048410+00:00, run_duration=0.464826, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=42, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-08 21:33:47.041028+00:00, queued_by_job_id=33, pid=96310
Dag run  in running state
Dag information Queued at: 2025-04-08 21:36:04.145214+00:00 hash info: 072245be002b3cf60ac84f51d56fa6a8
[2025-04-08T21:36:04.610+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T21:36:04.125982+00:00 [scheduled]>
[2025-04-08T21:36:04.611+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T21:36:04.612+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T21:36:04.125982+00:00 [scheduled]>
[2025-04-08T21:36:04.616+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T21:36:04.125982+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T21:36:04.617+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_prices', run_id='manual__2025-04-08T21:36:04.125982+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-08T21:36:04.617+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_prices', 'manual__2025-04-08T21:36:04.125982+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:36:04.621+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_prices', 'manual__2025-04-08T21:36:04.125982+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:36:06.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T21:36:07.507+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T21:36:07.520+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T21:36:07.521+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:36:07.526+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:36:07.602+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:36:07.630+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:36:07.681+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_prices manual__2025-04-08T21:36:04.125982+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T21:36:12.132+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_prices', run_id='manual__2025-04-08T21:36:04.125982+00:00', try_number=1, map_index=-1)
[2025-04-08T21:36:12.141+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_prices, run_id=manual__2025-04-08T21:36:04.125982+00:00, map_index=-1, run_start_date=2025-04-08 21:36:07.776788+00:00, run_end_date=2025-04-08 21:36:11.251698+00:00, run_duration=3.47491, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=43, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-08 21:36:04.613204+00:00, queued_by_job_id=33, pid=98422
[2025-04-08T21:36:12.319+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:36:04.125982+00:00 [scheduled]>
[2025-04-08T21:36:12.320+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T21:36:12.320+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:36:04.125982+00:00 [scheduled]>
[2025-04-08T21:36:12.324+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:36:04.125982+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T21:36:12.325+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T21:36:04.125982+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-08T21:36:12.325+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T21:36:04.125982+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:36:12.329+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T21:36:04.125982+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:36:14.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T21:36:15.450+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T21:36:15.464+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T21:36:15.465+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:36:15.470+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:36:15.549+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:36:15.577+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:36:15.628+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:36:04.125982+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T21:36:17.102+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T21:36:04.125982+00:00', try_number=1, map_index=-1)
[2025-04-08T21:36:17.111+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=manual__2025-04-08T21:36:04.125982+00:00, map_index=-1, run_start_date=2025-04-08 21:36:15.735174+00:00, run_end_date=2025-04-08 21:36:16.100075+00:00, run_duration=0.364901, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=44, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-08 21:36:12.322131+00:00, queued_by_job_id=33, pid=98538
[2025-04-08T21:38:47.036+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T21:38:52.100+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:33:38.685111+00:00 [scheduled]>
[2025-04-08T21:38:52.101+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T21:38:52.101+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:33:38.685111+00:00 [scheduled]>
[2025-04-08T21:38:52.104+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:33:38.685111+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T21:38:52.104+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T21:33:38.685111+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-08T21:38:52.105+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T21:33:38.685111+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:38:52.108+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T21:33:38.685111+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:38:54.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T21:38:55.063+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T21:38:55.083+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T21:38:55.084+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:38:55.092+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:38:55.215+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:38:55.245+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:38:55.295+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:33:38.685111+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T21:38:56.579+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T21:33:38.685111+00:00', try_number=2, map_index=-1)
[2025-04-08T21:38:56.585+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=manual__2025-04-08T21:33:38.685111+00:00, map_index=-1, run_start_date=2025-04-08 21:38:55.426915+00:00, run_end_date=2025-04-08 21:38:55.742586+00:00, run_duration=0.315671, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=45, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-08 21:38:52.102689+00:00, queued_by_job_id=33, pid=100446
[2025-04-08T21:38:56.654+0000] {dagrun.py:823} ERROR - Marking run <DagRun Download_Stock_Price @ 2025-04-08 21:33:38.685111+00:00: manual__2025-04-08T21:33:38.685111+00:00, state:running, queued_at: 2025-04-08 21:33:38.738092+00:00. externally triggered: True> failed
Dag run  in failure state
Dag information:Download_Stock_Price Run id: manual__2025-04-08T21:33:38.685111+00:00 external trigger: True
Failed with message: task_failure
[2025-04-08T21:38:56.655+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-08 21:33:38.685111+00:00, run_id=manual__2025-04-08T21:33:38.685111+00:00, run_start_date=2025-04-08 21:33:39.292673+00:00, run_end_date=2025-04-08 21:38:56.654951+00:00, run_duration=317.362278, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-04-07 21:33:38.685111+00:00, data_interval_end=2025-04-08 21:33:38.685111+00:00, dag_hash=072245be002b3cf60ac84f51d56fa6a8
[2025-04-08T21:41:16.783+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:36:04.125982+00:00 [scheduled]>
[2025-04-08T21:41:16.784+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T21:41:16.785+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:36:04.125982+00:00 [scheduled]>
[2025-04-08T21:41:16.788+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:36:04.125982+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T21:41:16.789+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T21:36:04.125982+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-08T21:41:16.789+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T21:36:04.125982+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:41:16.794+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T21:36:04.125982+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:41:19.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T21:41:20.070+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T21:41:20.090+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T21:41:20.091+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:41:20.100+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:41:20.208+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:41:20.256+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:41:20.328+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:36:04.125982+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T21:41:21.557+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T21:36:04.125982+00:00', try_number=2, map_index=-1)
[2025-04-08T21:41:21.563+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=manual__2025-04-08T21:36:04.125982+00:00, map_index=-1, run_start_date=2025-04-08 21:41:20.454402+00:00, run_end_date=2025-04-08 21:41:20.724354+00:00, run_duration=0.269952, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=46, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-08 21:41:16.786198+00:00, queued_by_job_id=33, pid=102153
[2025-04-08T21:41:21.629+0000] {dagrun.py:823} ERROR - Marking run <DagRun Download_Stock_Price @ 2025-04-08 21:36:04.125982+00:00: manual__2025-04-08T21:36:04.125982+00:00, state:running, queued_at: 2025-04-08 21:36:04.145214+00:00. externally triggered: True> failed
Dag run  in failure state
Dag information:Download_Stock_Price Run id: manual__2025-04-08T21:36:04.125982+00:00 external trigger: True
Failed with message: task_failure
[2025-04-08T21:41:21.630+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-08 21:36:04.125982+00:00, run_id=manual__2025-04-08T21:36:04.125982+00:00, run_start_date=2025-04-08 21:36:04.544684+00:00, run_end_date=2025-04-08 21:41:21.630215+00:00, run_duration=317.085531, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-04-07 21:36:04.125982+00:00, data_interval_end=2025-04-08 21:36:04.125982+00:00, dag_hash=072245be002b3cf60ac84f51d56fa6a8
[2025-04-08T21:43:47.083+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
Dag run  in running state
Dag information Queued at: 2025-04-08 21:45:47.278754+00:00 hash info: 54ce59dcbd7f15b5e14e6e1f366bf7a0
[2025-04-08T21:45:47.376+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_price manual__2025-04-08T21:45:47.258660+00:00 [scheduled]>
[2025-04-08T21:45:47.376+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T21:45:47.377+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_price manual__2025-04-08T21:45:47.258660+00:00 [scheduled]>
[2025-04-08T21:45:47.379+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_price manual__2025-04-08T21:45:47.258660+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T21:45:47.380+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='manual__2025-04-08T21:45:47.258660+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-08T21:45:47.380+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'manual__2025-04-08T21:45:47.258660+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:45:47.383+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'manual__2025-04-08T21:45:47.258660+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:45:49.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T21:45:49.986+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T21:45:50.001+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T21:45:50.001+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:45:50.007+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:45:50.090+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:45:50.120+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:45:50.170+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_price manual__2025-04-08T21:45:47.258660+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T21:45:56.344+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='manual__2025-04-08T21:45:47.258660+00:00', try_number=1, map_index=-1)
[2025-04-08T21:45:56.352+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_price, run_id=manual__2025-04-08T21:45:47.258660+00:00, map_index=-1, run_start_date=2025-04-08 21:45:50.264587+00:00, run_end_date=2025-04-08 21:45:54.696089+00:00, run_duration=4.431502, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=47, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-08 21:45:47.377971+00:00, queued_by_job_id=33, pid=105760
[2025-04-08T21:45:56.461+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:45:47.258660+00:00 [scheduled]>
[2025-04-08T21:45:56.461+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T21:45:56.462+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:45:47.258660+00:00 [scheduled]>
[2025-04-08T21:45:56.465+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:45:47.258660+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T21:45:56.465+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T21:45:47.258660+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-08T21:45:56.466+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T21:45:47.258660+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:45:56.468+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T21:45:47.258660+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:45:58.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T21:45:59.191+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T21:45:59.205+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T21:45:59.206+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:45:59.211+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:45:59.293+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:45:59.324+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:45:59.373+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:45:47.258660+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T21:46:00.626+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T21:45:47.258660+00:00', try_number=1, map_index=-1)
[2025-04-08T21:46:00.632+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=manual__2025-04-08T21:45:47.258660+00:00, map_index=-1, run_start_date=2025-04-08 21:45:59.474585+00:00, run_end_date=2025-04-08 21:45:59.863564+00:00, run_duration=0.388979, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=48, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-08 21:45:56.463522+00:00, queued_by_job_id=33, pid=105939
[2025-04-08T21:46:00.693+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T21:45:47.258660+00:00 [scheduled]>
[2025-04-08T21:46:00.694+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T21:46:00.694+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T21:45:47.258660+00:00 [scheduled]>
[2025-04-08T21:46:00.697+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T21:45:47.258660+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T21:46:00.697+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T21:45:47.258660+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-08T21:46:00.698+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T21:45:47.258660+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:46:00.701+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T21:45:47.258660+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:46:03.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T21:46:03.658+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T21:46:03.671+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T21:46:03.672+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:46:03.677+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:46:03.762+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:46:03.797+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:46:03.847+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T21:45:47.258660+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T21:46:05.076+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T21:45:47.258660+00:00', try_number=1, map_index=-1)
[2025-04-08T21:46:05.086+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=manual__2025-04-08T21:45:47.258660+00:00, map_index=-1, run_start_date=2025-04-08 21:46:03.950843+00:00, run_end_date=2025-04-08 21:46:04.244571+00:00, run_duration=0.293728, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=49, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-08 21:46:00.695429+00:00, queued_by_job_id=33, pid=106018
[2025-04-08T21:46:05.153+0000] {dagrun.py:854} INFO - Marking run <DagRun Download_Stock_Price @ 2025-04-08 21:45:47.258660+00:00: manual__2025-04-08T21:45:47.258660+00:00, state:running, queued_at: 2025-04-08 21:45:47.278754+00:00. externally triggered: True> successful
Dag run in success state
Dag run start:2025-04-08 21:45:47.343970+00:00 end:2025-04-08 21:46:05.154275+00:00
[2025-04-08T21:46:05.154+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-08 21:45:47.258660+00:00, run_id=manual__2025-04-08T21:45:47.258660+00:00, run_start_date=2025-04-08 21:45:47.343970+00:00, run_end_date=2025-04-08 21:46:05.154275+00:00, run_duration=17.810305, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-04-07 21:45:47.258660+00:00, data_interval_end=2025-04-08 21:45:47.258660+00:00, dag_hash=54ce59dcbd7f15b5e14e6e1f366bf7a0
[2025-04-08T21:48:47.129+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T21:51:19.969+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:51:20.113+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:51:20.387+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:51:22.255+0000] {manager.py:537} INFO - DAG Download_Stock_Price is missing and will be deactivated.
[2025-04-08T21:51:22.260+0000] {manager.py:549} INFO - Deactivated 1 DAGs which are no longer present in file.
[2025-04-08T21:51:22.265+0000] {manager.py:553} INFO - Deleted DAG Download_Stock_Price in serialized_dag table
[2025-04-08T21:51:30.358+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:51:30.678+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:51:30.709+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:52:01.454+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:52:01.523+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:52:01.599+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:52:31.977+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:52:32.048+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:52:32.667+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:53:02.757+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:53:02.911+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:53:03.722+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:53:33.577+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:53:33.712+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:53:34.460+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:53:47.175+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T21:54:04.337+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:54:04.398+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:54:05.093+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:54:35.025+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:54:35.606+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:54:35.646+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:55:05.906+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:55:06.438+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:55:06.756+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:55:36.613+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:55:38.019+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:55:38.028+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:56:07.910+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:56:08.561+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:56:09.263+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:56:38.438+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:56:38.963+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:56:40.760+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:57:09.863+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:57:10.012+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:57:11.279+0000] {processor.py:401} WARNING - Error when trying to pre-import module 'airflow.operators.email.operator' found in /home/gloria/workspace/airflow/dags/download_stock_price.py: No module named 'airflow.operators.email.operator'; 'airflow.operators.email' is not a package
[2025-04-08T21:58:47.219+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
Dag run  in running state
Dag information Queued at: 2025-04-08 21:59:54.122664+00:00 hash info: 54ce59dcbd7f15b5e14e6e1f366bf7a0
[2025-04-08T21:59:54.238+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_price manual__2025-04-08T21:59:54.104105+00:00 [scheduled]>
[2025-04-08T21:59:54.239+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T21:59:54.240+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_price manual__2025-04-08T21:59:54.104105+00:00 [scheduled]>
[2025-04-08T21:59:54.242+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_price manual__2025-04-08T21:59:54.104105+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T21:59:54.242+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='manual__2025-04-08T21:59:54.104105+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-08T21:59:54.243+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'manual__2025-04-08T21:59:54.104105+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:59:54.246+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'manual__2025-04-08T21:59:54.104105+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T21:59:56.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T21:59:57.085+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T21:59:57.101+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T21:59:57.101+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:59:57.110+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:59:57.229+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T21:59:57.275+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T21:59:57.344+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_price manual__2025-04-08T21:59:54.104105+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T22:00:02.794+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='manual__2025-04-08T21:59:54.104105+00:00', try_number=1, map_index=-1)
[2025-04-08T22:00:02.801+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_price, run_id=manual__2025-04-08T21:59:54.104105+00:00, map_index=-1, run_start_date=2025-04-08 21:59:57.460536+00:00, run_end_date=2025-04-08 22:00:01.837237+00:00, run_duration=4.376701, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=50, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-08 21:59:54.240786+00:00, queued_by_job_id=33, pid=116594
[2025-04-08T22:00:02.892+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:59:54.104105+00:00 [scheduled]>
[2025-04-08T22:00:02.892+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T22:00:02.893+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:59:54.104105+00:00 [scheduled]>
[2025-04-08T22:00:02.896+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:59:54.104105+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T22:00:02.897+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T21:59:54.104105+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-08T22:00:02.897+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T21:59:54.104105+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T22:00:02.900+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T21:59:54.104105+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T22:00:04.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T22:00:05.614+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T22:00:05.628+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T22:00:05.628+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T22:00:05.634+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T22:00:05.717+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T22:00:05.746+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T22:00:05.796+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T21:59:54.104105+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T22:00:07.029+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T21:59:54.104105+00:00', try_number=1, map_index=-1)
[2025-04-08T22:00:07.036+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=manual__2025-04-08T21:59:54.104105+00:00, map_index=-1, run_start_date=2025-04-08 22:00:05.897965+00:00, run_end_date=2025-04-08 22:00:06.202554+00:00, run_duration=0.304589, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=51, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-08 22:00:02.894436+00:00, queued_by_job_id=33, pid=116715
[2025-04-08T22:00:07.099+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T21:59:54.104105+00:00 [scheduled]>
[2025-04-08T22:00:07.100+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T22:00:07.100+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T21:59:54.104105+00:00 [scheduled]>
[2025-04-08T22:00:07.102+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T21:59:54.104105+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T22:00:07.103+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T21:59:54.104105+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-08T22:00:07.104+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T21:59:54.104105+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T22:00:07.107+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T21:59:54.104105+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T22:00:09.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T22:00:10.112+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T22:00:10.126+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T22:00:10.126+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T22:00:10.132+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T22:00:10.211+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T22:00:10.239+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T22:00:10.290+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T21:59:54.104105+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T22:00:11.632+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T21:59:54.104105+00:00', try_number=1, map_index=-1)
[2025-04-08T22:00:11.639+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=manual__2025-04-08T21:59:54.104105+00:00, map_index=-1, run_start_date=2025-04-08 22:00:10.411442+00:00, run_end_date=2025-04-08 22:00:10.727443+00:00, run_duration=0.316001, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=52, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-08 22:00:07.101255+00:00, queued_by_job_id=33, pid=116793
[2025-04-08T22:00:11.691+0000] {dagrun.py:854} INFO - Marking run <DagRun Download_Stock_Price @ 2025-04-08 21:59:54.104105+00:00: manual__2025-04-08T21:59:54.104105+00:00, state:running, queued_at: 2025-04-08 21:59:54.122664+00:00. externally triggered: True> successful
Dag run in success state
Dag run start:2025-04-08 21:59:54.204924+00:00 end:2025-04-08 22:00:11.691857+00:00
[2025-04-08T22:00:11.692+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-08 21:59:54.104105+00:00, run_id=manual__2025-04-08T21:59:54.104105+00:00, run_start_date=2025-04-08 21:59:54.204924+00:00, run_end_date=2025-04-08 22:00:11.691857+00:00, run_duration=17.486933, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-04-07 21:59:54.104105+00:00, data_interval_end=2025-04-08 21:59:54.104105+00:00, dag_hash=54ce59dcbd7f15b5e14e6e1f366bf7a0
Dag run  in running state
Dag information Queued at: 2025-04-08 22:01:19.098607+00:00 hash info: 3099ed8f27d24188c484a1d2876267a2
[2025-04-08T22:01:19.444+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_price manual__2025-04-08T22:01:19.080962+00:00 [scheduled]>
[2025-04-08T22:01:19.445+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T22:01:19.445+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_price manual__2025-04-08T22:01:19.080962+00:00 [scheduled]>
[2025-04-08T22:01:19.452+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_price manual__2025-04-08T22:01:19.080962+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T22:01:19.453+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='manual__2025-04-08T22:01:19.080962+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-08T22:01:19.454+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'manual__2025-04-08T22:01:19.080962+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T22:01:19.460+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'manual__2025-04-08T22:01:19.080962+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T22:01:21.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T22:01:21.979+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T22:01:21.992+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T22:01:21.993+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T22:01:21.998+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T22:01:22.081+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T22:01:22.110+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T22:01:22.160+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_price manual__2025-04-08T22:01:19.080962+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T22:01:27.098+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='manual__2025-04-08T22:01:19.080962+00:00', try_number=1, map_index=-1)
[2025-04-08T22:01:27.108+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_price, run_id=manual__2025-04-08T22:01:19.080962+00:00, map_index=-1, run_start_date=2025-04-08 22:01:22.255968+00:00, run_end_date=2025-04-08 22:01:25.939090+00:00, run_duration=3.683122, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=53, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-08 22:01:19.447025+00:00, queued_by_job_id=33, pid=117671
[2025-04-08T22:01:27.212+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T22:01:19.080962+00:00 [scheduled]>
[2025-04-08T22:01:27.213+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T22:01:27.213+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T22:01:19.080962+00:00 [scheduled]>
[2025-04-08T22:01:27.216+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T22:01:19.080962+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T22:01:27.217+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T22:01:19.080962+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-08T22:01:27.217+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T22:01:19.080962+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T22:01:27.221+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'manual__2025-04-08T22:01:19.080962+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T22:01:29.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T22:01:30.163+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T22:01:30.188+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T22:01:30.190+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T22:01:30.200+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T22:01:30.342+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T22:01:30.391+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T22:01:30.510+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database manual__2025-04-08T22:01:19.080962+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T22:01:32.556+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='manual__2025-04-08T22:01:19.080962+00:00', try_number=1, map_index=-1)
[2025-04-08T22:01:32.570+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=manual__2025-04-08T22:01:19.080962+00:00, map_index=-1, run_start_date=2025-04-08 22:01:30.694624+00:00, run_end_date=2025-04-08 22:01:31.505015+00:00, run_duration=0.810391, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=54, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-08 22:01:27.214724+00:00, queued_by_job_id=33, pid=117798
[2025-04-08T22:01:32.699+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T22:01:19.080962+00:00 [scheduled]>
[2025-04-08T22:01:32.700+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-08T22:01:32.701+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T22:01:19.080962+00:00 [scheduled]>
[2025-04-08T22:01:32.705+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T22:01:19.080962+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-08T22:01:32.707+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T22:01:19.080962+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-08T22:01:32.710+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T22:01:19.080962+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T22:01:32.714+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'manual__2025-04-08T22:01:19.080962+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-08T22:01:35.013+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-08T22:01:35.728+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-08T22:01:35.743+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-08T22:01:35.744+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T22:01:35.749+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T22:01:35.829+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-08T22:01:35.857+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-08T22:01:35.908+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price manual__2025-04-08T22:01:19.080962+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-08T22:01:37.157+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='manual__2025-04-08T22:01:19.080962+00:00', try_number=1, map_index=-1)
[2025-04-08T22:01:37.164+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=manual__2025-04-08T22:01:19.080962+00:00, map_index=-1, run_start_date=2025-04-08 22:01:36.010758+00:00, run_end_date=2025-04-08 22:01:36.291212+00:00, run_duration=0.280454, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=55, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-08 22:01:32.702695+00:00, queued_by_job_id=33, pid=117886
[2025-04-08T22:01:37.215+0000] {dagrun.py:854} INFO - Marking run <DagRun Download_Stock_Price @ 2025-04-08 22:01:19.080962+00:00: manual__2025-04-08T22:01:19.080962+00:00, state:running, queued_at: 2025-04-08 22:01:19.098607+00:00. externally triggered: True> successful
Dag run in success state
Dag run start:2025-04-08 22:01:19.404181+00:00 end:2025-04-08 22:01:37.215937+00:00
[2025-04-08T22:01:37.216+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-08 22:01:19.080962+00:00, run_id=manual__2025-04-08T22:01:19.080962+00:00, run_start_date=2025-04-08 22:01:19.404181+00:00, run_end_date=2025-04-08 22:01:37.215937+00:00, run_duration=17.811756, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-04-07 22:01:19.080962+00:00, data_interval_end=2025-04-08 22:01:19.080962+00:00, dag_hash=3099ed8f27d24188c484a1d2876267a2
[2025-04-08T22:03:47.259+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T22:08:47.312+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T22:13:47.393+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T22:18:47.453+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T22:23:47.504+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T22:28:47.551+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T22:33:47.609+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T22:38:47.653+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T22:43:47.699+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T22:48:47.745+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T22:53:47.800+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T22:58:47.819+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T23:03:47.916+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T23:08:47.968+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T23:13:48.010+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T23:18:48.052+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T23:23:48.096+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T23:28:48.143+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T23:33:48.205+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T23:38:48.251+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T23:43:48.292+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T23:48:48.343+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T23:53:48.396+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-08T23:58:48.446+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T00:00:00.322+0000] {scheduler_job_runner.py:1526} INFO - DAG Download_Stock_Price is at (or above) max_active_runs (1 of 1), not creating any more runs
Dag run  in running state
Dag information Queued at: 2025-04-09 00:00:00.308023+00:00 hash info: 3099ed8f27d24188c484a1d2876267a2
[2025-04-09T00:00:00.371+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.download_price scheduled__2025-04-08T00:00:00+00:00 [scheduled]>
[2025-04-09T00:00:00.372+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T00:00:00.372+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.download_price scheduled__2025-04-08T00:00:00+00:00 [scheduled]>
[2025-04-09T00:00:00.375+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.download_price scheduled__2025-04-08T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T00:00:00.375+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='scheduled__2025-04-08T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-04-09T00:00:00.375+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'scheduled__2025-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T00:00:00.379+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'download_price', 'scheduled__2025-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T00:00:02.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T00:00:03.587+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T00:00:03.602+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T00:00:03.603+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T00:00:03.608+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T00:00:03.690+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T00:00:03.722+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T00:00:03.775+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.download_price scheduled__2025-04-08T00:00:00+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T00:00:08.241+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='download_price', run_id='scheduled__2025-04-08T00:00:00+00:00', try_number=1, map_index=-1)
[2025-04-09T00:00:08.247+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=download_price, run_id=scheduled__2025-04-08T00:00:00+00:00, map_index=-1, run_start_date=2025-04-09 00:00:03.891267+00:00, run_end_date=2025-04-09 00:00:07.384057+00:00, run_duration=3.49279, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=56, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-04-09 00:00:00.373428+00:00, queued_by_job_id=33, pid=205702
[2025-04-09T00:00:08.336+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.save_to_database scheduled__2025-04-08T00:00:00+00:00 [scheduled]>
[2025-04-09T00:00:08.337+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T00:00:08.337+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.save_to_database scheduled__2025-04-08T00:00:00+00:00 [scheduled]>
[2025-04-09T00:00:08.339+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.save_to_database scheduled__2025-04-08T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T00:00:08.340+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='scheduled__2025-04-08T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-04-09T00:00:08.340+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'scheduled__2025-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T00:00:08.343+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'save_to_database', 'scheduled__2025-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T00:00:10.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T00:00:11.233+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T00:00:11.257+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T00:00:11.258+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T00:00:11.267+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T00:00:11.375+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T00:00:11.430+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T00:00:11.498+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.save_to_database scheduled__2025-04-08T00:00:00+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T00:00:12.683+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='save_to_database', run_id='scheduled__2025-04-08T00:00:00+00:00', try_number=1, map_index=-1)
[2025-04-09T00:00:12.689+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=save_to_database, run_id=scheduled__2025-04-08T00:00:00+00:00, map_index=-1, run_start_date=2025-04-09 00:00:11.590563+00:00, run_end_date=2025-04-09 00:00:11.895506+00:00, run_duration=0.304943, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=57, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-04-09 00:00:08.338261+00:00, queued_by_job_id=33, pid=205911
[2025-04-09T00:00:12.743+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: Download_Stock_Price.merge_stock_price scheduled__2025-04-08T00:00:00+00:00 [scheduled]>
[2025-04-09T00:00:12.744+0000] {scheduler_job_runner.py:507} INFO - DAG Download_Stock_Price has 0/16 running and queued tasks
[2025-04-09T00:00:12.744+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: Download_Stock_Price.merge_stock_price scheduled__2025-04-08T00:00:00+00:00 [scheduled]>
[2025-04-09T00:00:12.746+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: Download_Stock_Price.merge_stock_price scheduled__2025-04-08T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-04-09T00:00:12.747+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='scheduled__2025-04-08T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-04-09T00:00:12.747+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'scheduled__2025-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T00:00:12.750+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'Download_Stock_Price', 'merge_stock_price', 'scheduled__2025-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/download_stock_price.py']
[2025-04-09T00:00:14.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/gloria/workspace/airflow/dags/download_stock_price.py
[2025-04-09T00:00:15.187+0000] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2025-04-09T00:00:15.202+0000] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/home/gloria/airflow_env/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2025-04-09T00:00:15.203+0000] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T00:00:15.209+0000] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T00:00:15.289+0000] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2025-04-09T00:00:15.318+0000] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2025-04-09T00:00:15.365+0000] {task_command.py:467} INFO - Running <TaskInstance: Download_Stock_Price.merge_stock_price scheduled__2025-04-08T00:00:00+00:00 [queued]> on host instance-20250307-222520.us-central1-a.c.esoteric-realm-448604-v0.internal
[2025-04-09T00:00:16.673+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Download_Stock_Price', task_id='merge_stock_price', run_id='scheduled__2025-04-08T00:00:00+00:00', try_number=1, map_index=-1)
[2025-04-09T00:00:16.680+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=Download_Stock_Price, task_id=merge_stock_price, run_id=scheduled__2025-04-08T00:00:00+00:00, map_index=-1, run_start_date=2025-04-09 00:00:15.458352+00:00, run_end_date=2025-04-09 00:00:15.754359+00:00, run_duration=0.296007, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=58, pool=default_pool, queue=default, priority_weight=1, operator=SQLExecuteQueryOperator, queued_dttm=2025-04-09 00:00:12.745323+00:00, queued_by_job_id=33, pid=205948
[2025-04-09T00:00:16.727+0000] {dagrun.py:854} INFO - Marking run <DagRun Download_Stock_Price @ 2025-04-08 00:00:00+00:00: scheduled__2025-04-08T00:00:00+00:00, state:running, queued_at: 2025-04-09 00:00:00.308023+00:00. externally triggered: False> successful
Dag run in success state
Dag run start:2025-04-09 00:00:00.336000+00:00 end:2025-04-09 00:00:16.728610+00:00
[2025-04-09T00:00:16.728+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=Download_Stock_Price, execution_date=2025-04-08 00:00:00+00:00, run_id=scheduled__2025-04-08T00:00:00+00:00, run_start_date=2025-04-09 00:00:00.336000+00:00, run_end_date=2025-04-09 00:00:16.728610+00:00, run_duration=16.39261, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-04-08 00:00:00+00:00, data_interval_end=2025-04-09 00:00:00+00:00, dag_hash=af8f1f5b3108ff7d6b9f0fa1283d3a20
[2025-04-09T00:00:16.733+0000] {dag.py:4180} INFO - Setting next_dagrun for Download_Stock_Price to 2025-04-09 00:00:00+00:00, run_after=2025-04-10 00:00:00+00:00
[2025-04-09T00:03:48.498+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T00:08:48.547+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T00:13:48.596+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T00:18:48.647+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T00:23:48.695+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T00:28:48.741+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T00:33:48.783+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T00:38:48.825+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T00:43:48.878+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T00:48:48.966+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T00:53:49.024+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T00:58:49.073+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T01:03:49.117+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T01:08:49.189+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T01:13:49.241+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T01:18:49.286+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T01:23:49.372+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T01:28:49.439+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T01:33:49.501+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-04-09T01:38:49.555+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
